{
 "cells": [
  {
   "cell_type": "code",
   "id": "4f0b6e6b-ff4d-432f-a4c0-9f18b0c942f2",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logging.info(\"Multi-GPU LightGBM GridSearchCV\")\n",
    "\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    df = pm4py.convert_to_dataframe(log)\n",
    "    df = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "    return df\n",
    "\n",
    "df = import_xes(\"BPI Challenge 2018.xes\")\n",
    "logging.info(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "le_activity = LabelEncoder()\n",
    "df['concept:name'] = le_activity.fit_transform(df['concept:name'].astype(str))\n",
    "num_classes = len(le_activity.classes_)\n",
    "\n",
    "def create_activity_sequences_encoded(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, group in df.groupby('org:resource'):\n",
    "        acts = group['concept:name'].values\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df[\"next_activity\"] = next_activities\n",
    "    seq_df[\"org:resource\"] = resources\n",
    "    return seq_df\n",
    "\n",
    "def oversample_proportional_safe(X, y):\n",
    "    y_series = pd.Series(y)\n",
    "    counts = y_series.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        mask = (y_series == cls)\n",
    "        X_cls = X[mask]\n",
    "        y_cls = y_series[mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    return np.vstack(X_resampled), np.hstack(y_resampled)\n",
    "\n",
    "def run_experiment(df, prefix_length, gpu_id=0):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    logging.info(f\"\\nüéØ Running prefix={prefix_length} on GPU {gpu_id}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    seq_df = create_activity_sequences_encoded(df, prefix_length)\n",
    "    if seq_df.empty:\n",
    "        logging.warning(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: insufficient data.\")\n",
    "        return None\n",
    "\n",
    "    X = seq_df[[f\"activity_{i+1}\" for i in range(prefix_length)]].values\n",
    "    y = seq_df[\"next_activity\"].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    X_train, y_train = oversample_proportional_safe(X_train, y_train)\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        boosting_type='gbdt',\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        n_jobs=1,  # one GPU per process\n",
    "        free_raw_data=False\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_child_samples': [10, 20],\n",
    "        'min_split_gain': [0.0, 0.1]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=2,\n",
    "        verbose=1,\n",
    "        n_jobs=1  # one GPU per process\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(X_train, y_train)  \n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    runtime = round(time.time() - start_time, 2)\n",
    "    logging.info(f\"üèÜ Best params for prefix={prefix_length}: {grid.best_params_}\")\n",
    "    logging.info(f\"‚è± Runtime: {runtime}s, GPU {gpu_id}\")\n",
    "\n",
    "    os.makedirs(\"results/BPIC2018/LightGBM/Baseline encoding\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2018/LightGBM/Baseline encoding/lightgbm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_hyperparameters\": grid.best_params_,\n",
    "            \"metrics\": metrics,\n",
    "            \"runtime_s\": runtime\n",
    "        }, f, indent=4)\n",
    "\n",
    "    return {\"prefix_length\": prefix_length, \"metrics\": metrics, \"runtime_s\": runtime}\n",
    "\n",
    "sequence_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000, 2500]\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_experiment)(df, seq_len, gpu_id=i % 4)\n",
    "    for i, seq_len in enumerate(sequence_lengths)\n",
    ")\n",
    "\n",
    "logging.info(\"All GPU GridSearch experiments completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d641ea6-a2ac-4aec-9684-bac7e22cd467",
   "metadata": {},
   "source": [
    "#SCap\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logging.info(\"Multi-GPU LightGBM GridSearchCV with RA binary features\")\n",
    "\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    df = pm4py.convert_to_dataframe(log)\n",
    "    df = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "    return df\n",
    "\n",
    "df = import_xes(\"BPI Challenge 2018.xes\")\n",
    "logging.info(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "le_activity = LabelEncoder()\n",
    "df['concept:name'] = le_activity.fit_transform(df['concept:name'].astype(str))\n",
    "num_classes = len(le_activity.classes_)\n",
    "\n",
    "def create_ra_binary(log):\n",
    "    ra_counts = log.pivot_table(\n",
    "        index='org:resource', columns='concept:name', aggfunc='size', fill_value=0\n",
    "    ).reset_index()\n",
    "    ra_bin = ra_counts.copy()\n",
    "    ra_bin.iloc[:, 1:] = (ra_bin.iloc[:, 1:] > 0).astype(int)\n",
    "    return ra_bin, ra_counts.columns[1:].tolist()\n",
    "\n",
    "ra_binary, ra_activities = create_ra_binary(df)\n",
    "\n",
    "def create_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, g in df.groupby('org:resource'):\n",
    "        acts = g['concept:name'].values\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df['next_activity'] = next_activities\n",
    "    seq_df['org:resource'] = resources\n",
    "    return seq_df\n",
    "\n",
    "def oversample_proportional_safe(X, y):\n",
    "    y_series = pd.Series(y)\n",
    "    counts = y_series.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        mask = (y_series == cls)\n",
    "        X_cls = X[mask]\n",
    "        y_cls = y_series[mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    return np.vstack(X_resampled), np.hstack(y_resampled)\n",
    "\n",
    "def run_experiment(df, prefix_length, gpu_id=0):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    logging.info(f\"\\nüéØ Running prefix={prefix_length} on GPU {gpu_id}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    seq_df = create_sequences(df, prefix_length)\n",
    "    if seq_df.empty:\n",
    "        logging.warning(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: insufficient data.\")\n",
    "        return None\n",
    "\n",
    "    ra_filtered = ra_binary[ra_binary['org:resource'].isin(seq_df['org:resource'])].reset_index(drop=True)\n",
    "    merged_df = pd.concat([seq_df.reset_index(drop=True), ra_filtered.iloc[:, 1:]], axis=1)\n",
    "\n",
    "    X_cols = [f\"activity_{i+1}\" for i in range(prefix_length)] + ra_activities\n",
    "    X = merged_df[X_cols].values\n",
    "    y = merged_df['next_activity'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    X_train, y_train = oversample_proportional_safe(X_train, y_train)\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        boosting_type='gbdt',\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_child_samples': [10, 20],\n",
    "        'min_split_gain': [0.0, 0.1]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=2,\n",
    "        verbose=1,\n",
    "        n_jobs=1  # one GPU per process\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    runtime = round(time.time() - start_time, 2)\n",
    "    logging.info(f\"üèÜ Best params for prefix={prefix_length}: {grid.best_params_}\")\n",
    "    logging.info(f\"‚è± Runtime: {runtime}s, GPU {gpu_id}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2018/LightGBM/SCap\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2018/LightGBM/SCap/lightgbm_ra_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_hyperparameters\": grid.best_params_,\n",
    "            \"metrics\": metrics,\n",
    "            \"runtime_s\": runtime\n",
    "        }, f, indent=4)\n",
    "\n",
    "    return {\"prefix_length\": prefix_length, \"metrics\": metrics, \"runtime_s\": runtime}\n",
    "\n",
    "sequence_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000, 2500]\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_experiment)(df, seq_len, gpu_id=i % 4)\n",
    "    for i, seq_len in enumerate(sequence_lengths)\n",
    ")\n",
    "\n",
    "logging.info(\"All GPU GridSearch + RA matrix experiments completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ba1f8d0-f1c2-4485-81cf-09d5a3984e06",
   "metadata": {},
   "source": [
    "# S2g\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logging.info(\"Multi-GPU LightGBM GridSearchCV with Activity Transitions only\")\n",
    "\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    df = pm4py.convert_to_dataframe(log)\n",
    "    df = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "    return df\n",
    "\n",
    "df = import_xes(\"BPI Challenge 2018.xes\")\n",
    "logging.info(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "le_activity = LabelEncoder()\n",
    "df['concept:name'] = le_activity.fit_transform(df['concept:name'].astype(str))\n",
    "num_classes = len(le_activity.classes_)\n",
    "\n",
    "def create_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, g in df.groupby('org:resource'):\n",
    "        acts = g['concept:name'].values\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df['next_activity'] = next_activities\n",
    "    seq_df['org:resource'] = resources\n",
    "    return seq_df\n",
    "\n",
    "def create_transition_features(seq_df):\n",
    "    activity_cols = [c for c in seq_df.columns if c.startswith('activity_')]\n",
    "    unique_activities = sorted(set(seq_df[activity_cols].values.flatten()))\n",
    "    all_transitions = [(a, b) for a in unique_activities for b in unique_activities]\n",
    "    transition_features = []\n",
    "    for _, row in seq_df.iterrows():\n",
    "        transitions = defaultdict(int)\n",
    "        acts = row[activity_cols].tolist()\n",
    "        for i in range(len(acts)-1):\n",
    "            transitions[(acts[i], acts[i+1])] += 1\n",
    "        row_counts = {f\"{a}->{b}\": transitions.get((a,b),0) for (a,b) in all_transitions}\n",
    "        transition_features.append(row_counts)\n",
    "    return pd.concat([seq_df.reset_index(drop=True), pd.DataFrame(transition_features)], axis=1)\n",
    "\n",
    "def oversample_proportional_safe(X, y):\n",
    "    y_series = pd.Series(y)\n",
    "    counts = y_series.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        mask = (y_series == cls)\n",
    "        X_cls = X[mask]\n",
    "        y_cls = y_series[mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    return np.vstack(X_resampled), np.hstack(y_resampled)\n",
    "\n",
    "def run_experiment(df, prefix_length, gpu_id=0):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    logging.info(f\"\\nüéØ Running prefix={prefix_length} on GPU {gpu_id}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    seq_df = create_sequences(df, prefix_length)\n",
    "    if seq_df.empty:\n",
    "        logging.warning(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: insufficient data.\")\n",
    "        return None\n",
    "\n",
    "    # Add transition features\n",
    "    seq_df = create_transition_features(seq_df)\n",
    "\n",
    "    for col in seq_df.columns:\n",
    "        if seq_df[col].dtype == 'object':\n",
    "            seq_df[col] = LabelEncoder().fit_transform(seq_df[col].astype(str))\n",
    "\n",
    "    # Split features/labels\n",
    "    X_cols = [c for c in seq_df.columns if c not in ['next_activity','org:resource']]\n",
    "    X = seq_df[X_cols].values\n",
    "    y = seq_df['next_activity'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    X_train, y_train = oversample_proportional_safe(X_train, y_train)\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        boosting_type='gbdt',\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_child_samples': [10, 20],\n",
    "        'min_split_gain': [0.0, 0.1]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(model, param_grid, scoring='accuracy', cv=2, verbose=1, n_jobs=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    runtime = round(time.time() - start_time, 2)\n",
    "    logging.info(f\"üèÜ Best params for prefix={prefix_length}: {grid.best_params_}\")\n",
    "    logging.info(f\"‚è± Runtime: {runtime}s, GPU {gpu_id}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2018/LightGBM/S2g\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2018/LightGBM/S2g/lightgbm_trans_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_hyperparameters\": grid.best_params_,\n",
    "            \"metrics\": metrics,\n",
    "            \"runtime_s\": runtime\n",
    "        }, f, indent=4)\n",
    "\n",
    "    return {\"prefix_length\": prefix_length, \"metrics\": metrics, \"runtime_s\": runtime}\n",
    "\n",
    "sequence_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000, 2500]\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_experiment)(df, seq_len, gpu_id=i % 4)\n",
    "    for i, seq_len in enumerate(sequence_lengths)\n",
    ")\n",
    "\n",
    "logging.info(\"All GPU GridSearch + Transition-only experiments completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91b3cdf5-9222-4c13-abba-47ef4b5060f9",
   "metadata": {},
   "source": [
    "#S2gR\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logging.info(\"Multi-GPU LightGBM GridSearchCV with Transition + Repeat Features\")\n",
    "\n",
    "import pm4py\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    df = pm4py.convert_to_dataframe(log)\n",
    "    df = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = import_xes(\"BPI_Challenge_2013_incidents.xes\")\n",
    "logging.info(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "le_activity = LabelEncoder()\n",
    "df['concept:name'] = le_activity.fit_transform(df['concept:name'].astype(str))\n",
    "num_classes = len(le_activity.classes_)\n",
    "\n",
    "def create_activity_sequences_encoded(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, group in df.groupby('org:resource'):\n",
    "        acts = group['concept:name'].values\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df[\"next_activity\"] = next_activities\n",
    "    seq_df[\"org:resource\"] = resources\n",
    "    return seq_df\n",
    "\n",
    "def create_transition_and_repeat_features(seq_df):\n",
    "    activity_cols = [c for c in seq_df.columns if c.startswith('activity_')]\n",
    "    unique_activities = sorted(set(seq_df[activity_cols].values.flatten()))\n",
    "    all_transitions = [(a, b) for a in unique_activities for b in unique_activities]\n",
    "\n",
    "    transition_features = []\n",
    "    repeat_features = []\n",
    "\n",
    "    for _, row in seq_df.iterrows():\n",
    "        acts = row[activity_cols].tolist()\n",
    "        \n",
    "        # Transition counts\n",
    "        transitions = defaultdict(int)\n",
    "        for i in range(len(acts)-1):\n",
    "            transitions[(acts[i], acts[i+1])] += 1\n",
    "        row_transitions = {f\"{a}->{b}\": transitions.get((a,b), 0) for (a,b) in all_transitions}\n",
    "        transition_features.append(row_transitions)\n",
    "        \n",
    "        # Repeat pattern features\n",
    "        run_lengths = []\n",
    "        current_run = 1\n",
    "        for i in range(1, len(acts)):\n",
    "            if acts[i] == acts[i-1]:\n",
    "                current_run += 1\n",
    "            else:\n",
    "                run_lengths.append(current_run)\n",
    "                current_run = 1\n",
    "        run_lengths.append(current_run)\n",
    "        repeat_features.append({\n",
    "            \"avg_run_length\": np.mean(run_lengths),\n",
    "            \"num_runs\": len(run_lengths)\n",
    "        })\n",
    "\n",
    "    transitions_df = pd.DataFrame(transition_features)\n",
    "    repeat_df = pd.DataFrame(repeat_features)\n",
    "    return pd.concat([seq_df.reset_index(drop=True), transitions_df, repeat_df], axis=1)\n",
    "\n",
    "def oversample_proportional_safe(X, y):\n",
    "    y_series = pd.Series(y)\n",
    "    counts = y_series.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        mask = (y_series == cls)\n",
    "        X_cls = X[mask]\n",
    "        y_cls = y_series[mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    return np.vstack(X_resampled), np.hstack(y_resampled)\n",
    "\n",
    "\n",
    "def run_experiment(df, prefix_length, gpu_id=0):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    logging.info(f\"\\nüéØ Running prefix={prefix_length} on GPU {gpu_id}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    seq_df = create_activity_sequences_encoded(df, prefix_length)\n",
    "    if seq_df.empty:\n",
    "        logging.warning(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: insufficient data.\")\n",
    "        return None\n",
    "\n",
    "    # Add transition + repeat features\n",
    "    seq_df = create_transition_and_repeat_features(seq_df)\n",
    "\n",
    "    feature_cols = [c for c in seq_df.columns if c not in ['next_activity','org:resource']]\n",
    "    X = seq_df[feature_cols].values\n",
    "    y = seq_df[\"next_activity\"].values\n",
    "\n",
    "    # Split train/test BEFORE oversampling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Oversample training set only\n",
    "    X_train, y_train = oversample_proportional_safe(X_train, y_train)\n",
    "\n",
    "    # LightGBM model\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        boosting_type='gbdt',\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        n_jobs=1,  # one GPU per process\n",
    "        free_raw_data=False\n",
    "    )\n",
    "\n",
    "    # Parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_child_samples': [10, 20],\n",
    "        'min_split_gain': [0.0, 0.1]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=2,\n",
    "        verbose=1,\n",
    "        n_jobs=1  # one GPU per process\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    runtime = round(time.time() - start_time, 2)\n",
    "    logging.info(f\"üèÜ Best params for prefix={prefix_length}: {grid.best_params_}\")\n",
    "    logging.info(f\"‚è± Runtime: {runtime}s, GPU {gpu_id}\")\n",
    "\n",
    "    os.makedirs(\"results/BPIC2013/LightGBM/S2gR\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2013/LightGBM/S2gR/lightgbm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_hyperparameters\": grid.best_params_,\n",
    "            \"metrics\": metrics,\n",
    "            \"runtime_s\": runtime\n",
    "        }, f, indent=4)\n",
    "\n",
    "    return {\"prefix_length\": prefix_length, \"metrics\": metrics, \"runtime_s\": runtime}\n",
    "\n",
    "sequence_lengths = [10,20,30,40,50,75,100,125,150]\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_experiment)(df, seq_len, gpu_id=i % 4)\n",
    "    for i, seq_len in enumerate(sequence_lengths)\n",
    ")\n",
    "\n",
    "logging.info(\"All GPU GridSearch experiments completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
