{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T16:42:31.718124Z",
     "start_time": "2025-11-27T16:42:31.260161Z"
    }
   },
   "source": "import pm4py",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T16:42:36.477700Z",
     "start_time": "2025-11-27T16:42:33.616654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2013_incidents.xes\")"
   ],
   "id": "f14b9e1a404a451",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/pm4py/util/dt_parsing/parser.py:77: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7554 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a6c215b452e4dabaa2c66c7824f9b3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T16:43:12.251591Z",
     "start_time": "2025-11-27T16:43:12.214845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "df.head(10)"
   ],
   "id": "2aca6616ffd200e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      case:concept:name concept:name org:resource            time:timestamp\n",
       "4897        1-701284355     Accepted            - 2012-03-26 15:54:02+00:00\n",
       "4898        1-701284355     Accepted            - 2012-03-26 15:54:07+00:00\n",
       "8796        1-716650593     Accepted            - 2012-04-12 11:15:26+00:00\n",
       "13687       1-726974974     Accepted            - 2012-04-20 07:10:11+00:00\n",
       "8807        1-716650593     Accepted            - 2012-04-26 16:10:57+00:00\n",
       "21610       1-731896824     Accepted            - 2012-04-28 07:02:38+00:00\n",
       "33079       1-736602136       Queued            - 2012-05-02 13:30:22+00:00\n",
       "41404       1-738331603     Accepted            - 2012-05-02 13:32:32+00:00\n",
       "33083       1-736602136     Accepted            - 2012-05-02 14:51:19+00:00\n",
       "33084       1-736602136       Queued            - 2012-05-02 14:56:29+00:00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1-701284355</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-03-26 15:54:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>1-701284355</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-03-26 15:54:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>1-716650593</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-04-12 11:15:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>1-726974974</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-04-20 07:10:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>1-716650593</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-04-26 16:10:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1-731896824</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-04-28 07:02:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33079</th>\n",
       "      <td>1-736602136</td>\n",
       "      <td>Queued</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-05-02 13:30:22+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41404</th>\n",
       "      <td>1-738331603</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-05-02 13:32:32+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33083</th>\n",
       "      <td>1-736602136</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-05-02 14:51:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33084</th>\n",
       "      <td>1-736602136</td>\n",
       "      <td>Queued</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-05-02 14:56:29+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T16:43:14.952567Z",
     "start_time": "2025-11-27T16:43:14.762433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences = []\n",
    "    next_activities = []\n",
    "    resources = []\n",
    "\n",
    "    for case_id, case_df in df.groupby('concept:name'):\n",
    "        activities = case_df['concept:name'].values\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            prefix = activities[:prefix_length]\n",
    "            next_activity = activities[prefix_length]\n",
    "            sequences.append(prefix)\n",
    "            next_activities.append(next_activity)\n",
    "            resources.append(case_id)\n",
    "\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i + 1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "\n",
    "max_sequence_length = df.groupby('concept:name').size().max()\n",
    "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
    "\n",
    "# prefix_lengths = [10, 20, 30, 40, 50, 75, 100, 125, 150] #for BPIC2013 resources\n",
    "prefix_lengths = [10, 15, 20, 25, 30, 35, 40, 45, 50] #for BPIC2013 cases\n",
    "\n",
    "# prefix_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000] #for BPIC2017 resources\n",
    "# prefix_lengths = [10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80] #for BPIC2017 cases\n",
    "# prefix_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000, 2500] #for BPIC2018 resources\n",
    "# prefix_lengths = [100, 125, 150, 175, 200, 225, 250, 300, 350, 400, 450, 500, 600] #for BPIC2018 cases \n",
    "# prefix_lengths = [100, 150, 200, 300, 400, 500, 600, 700, 800] #for BPIC2019 resources\n",
    "# prefix_lengths = [100, 125, 150, 175, 200, 225, 250, 300, 400] #for BPIC2019 cases\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "\n",
    "    if sequences_df.empty:\n",
    "        print(f\"No valid sequences for prefix length {prefix_length}\")\n",
    "        results.append({'Prefix Length': prefix_length, 'Accuracy': None, 'Num Samples': 0})\n",
    "        continue\n",
    "\n",
    "    # Label encode activities\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_activities = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_activities)\n",
    "\n",
    "    for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # Define features and target\n",
    "    X = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)]]\n",
    "    y = sequences_df['next_activity']\n",
    "\n",
    "    # Handle rare classes\n",
    "    rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "    if len(rare_classes) > 0:\n",
    "        y = y.replace(rare_classes, -1)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Majority class predictor\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Save results\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Num Samples': len(sequences_df)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(\"majority_class_accuracies_BPIC2013_resource_new.xlsx\", index=False)\n",
    "\n",
    "print(\"Results saved to majority_class_accuracies.xlsx\")"
   ],
   "id": "4eb7a16e4fe93e64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 40117\n",
      "Results saved to majority_class_accuracies.xlsx\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T16:43:20.679141Z",
     "start_time": "2025-11-27T16:43:19.690771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def create_resource_sequences(df, prefix_length):\n",
    "    sequences = []\n",
    "    next_activities = []\n",
    "    resources = []\n",
    "\n",
    "    # group by resource instead of case\n",
    "    for resource, res_df in df.groupby('org:resource'):\n",
    "        # sort by timestamp\n",
    "        res_df = res_df.sort_values('time:timestamp')\n",
    "        activities = res_df['concept:name'].values\n",
    "\n",
    "        # same logic as before, but applied to resource traces\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            prefix = activities[:prefix_length]\n",
    "            next_activity = activities[prefix_length]\n",
    "\n",
    "            sequences.append(prefix)\n",
    "            next_activities.append(next_activity)\n",
    "            resources.append(resource)\n",
    "\n",
    "    # build DataFrame\n",
    "    sequences_df = pd.DataFrame(\n",
    "        sequences,\n",
    "        columns=[f\"activity_{i+1}\" for i in range(prefix_length)]\n",
    "    )\n",
    "    sequences_df[\"next_activity\"] = next_activities\n",
    "    sequences_df[\"org:resource\"] = resources\n",
    "\n",
    "    return sequences_df\n",
    "\n",
    "\n",
    "# --- Compute maximum prefix length per resource ---\n",
    "max_sequence_length = df.groupby(\"org:resource\").size().max()\n",
    "print(f\"Maximum resource-trace length: {max_sequence_length}\")\n",
    "\n",
    "\n",
    "# Example prefix lengths for resource-centric BPIC2013\n",
    "prefix_lengths = [10, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    sequences_df = create_resource_sequences(df, prefix_length)\n",
    "\n",
    "    if sequences_df.empty:\n",
    "        print(f\"No valid sequences for prefix length {prefix_length}\")\n",
    "        results.append({\n",
    "            \"Prefix Length\": prefix_length,\n",
    "            \"Accuracy\": None,\n",
    "            \"Num Samples\": 0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # label encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_acts = sequences_df[\n",
    "        [f\"activity_{i+1}\" for i in range(prefix_length)] + [\"next_activity\"]\n",
    "    ].values.flatten()\n",
    "\n",
    "    label_encoder.fit(all_acts)\n",
    "\n",
    "    for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + [\"next_activity\"]:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # features and target\n",
    "    X = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)]]\n",
    "    y = sequences_df[\"next_activity\"]\n",
    "\n",
    "    # replace rare classes with -1\n",
    "    rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "    if rare_classes:\n",
    "        y = y.replace(rare_classes, -1)\n",
    "\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # majority baseline\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # store results\n",
    "    results.append({\n",
    "        \"Prefix Length\": prefix_length,\n",
    "        \"Accuracy\": round(accuracy, 4),\n",
    "        \"Num Samples\": len(sequences_df)\n",
    "    })\n",
    "\n",
    "# save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(\"majority_class_accuracies_resource_centric.xlsx\", index=False)\n",
    "\n",
    "print(\"Saved: majority_class_accuracies_resource_centric.xlsx\")"
   ],
   "id": "441db052bfda55a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum resource-trace length: 6162\n",
      "Saved: majority_class_accuracies_resource_centric.xlsx\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
