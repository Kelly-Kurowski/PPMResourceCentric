{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faddb35-5881-4490-abdd-23a655ef15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üöÄ LSTM Baseline Encoding + Optuna (Leakage-Free)\n",
    "# =====================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --------------------------\n",
    "# Device setup\n",
    "# --------------------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2019.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        acts = resource_df['concept:name'].values\n",
    "        if len(acts) >= prefix_length + 1:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df['next_activity'] = next_activities\n",
    "    seq_df['org:resource'] = resources\n",
    "    return seq_df\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling (train only)\n",
    "# --------------------------\n",
    "def proportional_sampling(X, y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        if cls == -1:\n",
    "            continue\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / count))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    X_bal = np.vstack(X_resampled)\n",
    "    y_bal = np.hstack(y_resampled)\n",
    "    idx = np.random.permutation(len(y_bal))\n",
    "    return X_bal[idx], y_bal[idx]\n",
    "\n",
    "# --------------------------\n",
    "# LSTM model\n",
    "# --------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size//2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size//2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# --------------------------\n",
    "# Train function (with logging)\n",
    "# --------------------------\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=None):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            if (y_batch >= 0).sum() == 0:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            if torch.isnan(loss):\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_count = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                mask = y_batch >= 0\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "                output = model(X_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "                val_count += 1\n",
    "        val_loss /= max(val_count, 1)\n",
    "\n",
    "        print(f\"üåÄ Trial {trial_num} | Epoch {epoch+1}/{epochs} | Train Loss: {total_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# Run experiment\n",
    "# --------------------------\n",
    "def run_experiment(prefix_length):\n",
    "    print(f\"\\nüöÄ Running experiment: sequence length = {prefix_length}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "    if sequences_df.empty:\n",
    "        print(\"‚ö†Ô∏è Not enough sequences, skipping.\")\n",
    "        return\n",
    "\n",
    "    # Label encoding (fit only on training)\n",
    "    cols = [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']\n",
    "    all_acts = sequences_df[cols].values.flatten()\n",
    "    global_le = LabelEncoder()\n",
    "    global_le.fit(all_acts)\n",
    "\n",
    "    # Encode activities\n",
    "    for col in cols:\n",
    "        sequences_df[col] = global_le.transform(sequences_df[col])\n",
    "\n",
    "    X = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)]].values.astype(np.float32)\n",
    "    y = sequences_df['next_activity'].values.astype(np.int64)\n",
    "\n",
    "    # Handle rare classes\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    rare_labels = unique[counts < 2]\n",
    "    y = np.where(np.isin(y, rare_labels), -1, y)\n",
    "\n",
    "    # Train/Val split first (to avoid leakage)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Oversample training set only\n",
    "    X_train_res, y_train_res = proportional_sampling(X_train, y_train)\n",
    "    X_train_res = np.expand_dims(X_train_res, axis=2)\n",
    "    X_val = np.expand_dims(X_val, axis=2)\n",
    "\n",
    "    # Map valid classes to 0..N-1\n",
    "    valid_classes = np.unique(y_train_res[y_train_res >= 0])\n",
    "    num_classes = len(valid_classes)\n",
    "    label_map = {old: new for new, old in enumerate(valid_classes)}\n",
    "    y_train_res = np.array([label_map[v] if v >= 0 else -1 for v in y_train_res])\n",
    "    y_val = np.array([label_map[v] if v in label_map else -1 for v in y_val])\n",
    "\n",
    "    # --------------------------\n",
    "    # Optuna objective\n",
    "    # --------------------------\n",
    "    def objective(trial):\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 32, 192, step=32)\n",
    "        lr = trial.suggest_categorical(\"lr\", [1e-4, 5e-4, 1e-3])\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "        trial_num = trial.number + 1\n",
    "\n",
    "        print(f\"\\nüî• Starting Trial {trial_num} | hidden={hidden_size}, lr={lr}, opt={optimizer_name}\")\n",
    "\n",
    "        model = LSTMModel(X_train_res.shape[2], hidden_size, num_classes).to(device)\n",
    "        if optimizer_name == \"adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        elif optimizer_name == \"rmsprop\":\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train_res), torch.tensor(y_train_res)), batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "        model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=trial_num)\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        valid_mask = y_val >= 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, _ in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "        if valid_mask.sum() == 0:\n",
    "            return 0.0\n",
    "        return accuracy_score(y_val[valid_mask], np.array(y_pred)[valid_mask])\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=15, catch=(Exception,))\n",
    "\n",
    "    if len(study.trials) == 0 or study.best_trial is None:\n",
    "        print(\"‚ö†Ô∏è No successful trials. Skipping saving metrics.\")\n",
    "        return\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"üèÜ Best hyperparameters: {best_params}\")\n",
    "\n",
    "    # Final model training with best params\n",
    "    hidden_size = best_params[\"hidden_size\"]\n",
    "    lr = best_params[\"lr\"]\n",
    "    optimizer_name = best_params[\"optimizer\"]\n",
    "\n",
    "    model = LSTMModel(X_train_res.shape[2], hidden_size, num_classes).to(device)\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train_res), torch.tensor(y_train_res)), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "    model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=50, patience=5, trial_num=\"final\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    valid_mask = y_val >= 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_val[valid_mask], np.array(y_pred)[valid_mask]),\n",
    "        \"precision\": precision_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"num_samples\": len(y_train_res),\n",
    "        \"sequence_length\": prefix_length\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"sequence_length\": prefix_length,\n",
    "        \"best_hyperparameters\": best_params,\n",
    "        \"metrics\": metrics,\n",
    "        \"runtime_seconds\": round(time.time() - start_time, 2)\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"results/BPIC2019/LSTM model/Baseline encoding\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2019/LSTM model/Baseline encoding/lstm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"\\nüìä Evaluation Results for seq={prefix_length}:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"   {k}: {v:.4f}\")\n",
    "    print(f\"üíæ Results saved to {out_path}\")\n",
    "    print(f\"‚úÖ Experiment completed in {results['runtime_seconds']}s.\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# Run all sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "for seq_len in sequence_lengths:\n",
    "    run_experiment(seq_len)\n",
    "\n",
    "print(\"\\nüéØ All experiments completed! Results saved in /results/BPIC2019/LSTM model/Baseline encoding (leak-free)/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e219ac1-0823-4a7a-9596-f7e724f373d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üöÄ LSTM + Resource-Activity Binary + Optuna (Safe)\n",
    "# =====================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --------------------------\n",
    "# Environment & device setup\n",
    "# --------------------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "event_log = import_xes(\"BPI Challenge 2018.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Resource-Activity binary matrix\n",
    "# --------------------------\n",
    "def create_diversity_matrix(log):\n",
    "    activity_counts = log.pivot_table(\n",
    "        index='org:resource',\n",
    "        columns='concept:name',\n",
    "        aggfunc='size',\n",
    "        fill_value=0\n",
    "    )\n",
    "    activity_counts.reset_index(inplace=True)\n",
    "    return activity_counts\n",
    "\n",
    "ra_div_matrix = create_diversity_matrix(event_log)\n",
    "ra_div_binary = ra_div_matrix.copy()\n",
    "ra_div_binary.iloc[:, 1:] = (ra_div_binary.iloc[:, 1:] > 0).astype(int)\n",
    "activities = ra_div_matrix.columns[1:].tolist()\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        acts = resource_df['concept:name'].values\n",
    "        if len(acts) >= prefix_length + 1:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling\n",
    "# --------------------------\n",
    "def proportional_sampling(X, y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        if cls == -1:\n",
    "            continue  # skip ignored label\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / count))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    X_bal = np.vstack(X_resampled)\n",
    "    y_bal = np.hstack(y_resampled)\n",
    "    idx = np.random.permutation(len(y_bal))\n",
    "    return X_bal[idx], y_bal[idx]\n",
    "\n",
    "# --------------------------\n",
    "# PyTorch LSTM model\n",
    "# --------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size//2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size//2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# --------------------------\n",
    "# Train function (safe)\n",
    "# --------------------------\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            if (y_batch >= 0).sum() == 0:\n",
    "                continue  # skip batch if all labels are -1\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            if torch.isnan(loss):\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_count = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                mask = y_batch >= 0\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "                output = model(X_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "                val_count += 1\n",
    "        val_loss = val_loss / max(val_count, 1)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# Run experiment\n",
    "# --------------------------\n",
    "def run_experiment(prefix_length):\n",
    "    print(f\"\\nüöÄ Running experiment: sequence length = {prefix_length}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "    if sequences_df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping sequence length {prefix_length}: not enough data\")\n",
    "        return\n",
    "    \n",
    "    ra_filtered = ra_div_binary[ra_div_matrix['org:resource'].isin(sequences_df['org:resource'])].reset_index(drop=True)\n",
    "    merged_df = pd.concat([sequences_df.reset_index(drop=True), ra_filtered.iloc[:, 1:]], axis=1)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    all_acts = merged_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_acts)\n",
    "    for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']:\n",
    "        merged_df[col] = label_encoder.transform(merged_df[col])\n",
    "    \n",
    "    X = merged_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + activities].values.astype(np.float32)\n",
    "    y = merged_df['next_activity'].values.astype(np.int64)\n",
    "    \n",
    "    # Replace rare labels with -1\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    rare_labels = unique[counts < 2]\n",
    "    y = np.where(np.isin(y, rare_labels), -1, y)\n",
    "    \n",
    "    # Proportional sampling\n",
    "    X, y = proportional_sampling(X, y)\n",
    "    X = np.expand_dims(X, axis=2)\n",
    "    \n",
    "    # Random train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    valid_classes = np.unique(y[y >= 0])\n",
    "    num_classes = len(valid_classes)\n",
    "    label_map = {old: new for new, old in enumerate(valid_classes)}\n",
    "    y_train = np.array([label_map[v] if v >= 0 else -1 for v in y_train])\n",
    "    y_val = np.array([label_map[v] if v >= 0 else -1 for v in y_val])\n",
    "    \n",
    "    def objective(trial):\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 32, 192, step=32)\n",
    "        lr = trial.suggest_categorical(\"lr\", [1e-4, 5e-4, 1e-3])\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "        \n",
    "        model = LSTMModel(X_train.shape[2], hidden_size, num_classes).to(device)\n",
    "        if optimizer_name == \"adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        elif optimizer_name == \"rmsprop\":\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "        \n",
    "        model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        valid_mask = y_val >= 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "        if valid_mask.sum() == 0:\n",
    "            return 0.0\n",
    "        acc = accuracy_score(y_val[valid_mask], np.array(y_pred)[valid_mask])\n",
    "        return acc\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=15, catch=(Exception,))\n",
    "    \n",
    "    if len(study.trials) == 0 or study.best_trial is None:\n",
    "        print(\"‚ö†Ô∏è No successful trials. Skipping saving metrics.\")\n",
    "        return\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(f\"üèÜ Best hyperparameters for seq {prefix_length}: {best_params}\")\n",
    "    \n",
    "    # Final training with best params\n",
    "    hidden_size = best_params[\"hidden_size\"]\n",
    "    lr = best_params[\"lr\"]\n",
    "    optimizer_name = best_params[\"optimizer\"]\n",
    "    model = LSTMModel(X_train.shape[2], hidden_size, num_classes).to(device)\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "    model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=50, patience=5)\n",
    "    \n",
    "    # Metrics\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    valid_mask = y_val >= 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_val[valid_mask], np.array(y_pred)[valid_mask]),\n",
    "        \"precision\": precision_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_val[valid_mask], np.array(y_pred)[valid_mask], average=\"weighted\", zero_division=0),\n",
    "        \"num_samples\": len(y_train),\n",
    "        \"sequence_length\": prefix_length\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        \"sequence_length\": prefix_length,\n",
    "        \"best_hyperparameters\": best_params,\n",
    "        \"metrics\": metrics,\n",
    "        \"runtime_seconds\": round(time.time() - start_time, 2)\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"results/BPIC2018/LSTM model/SCap_check\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2018/LSTM model/SCap_check/lstm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"\\nüíæ Results saved to {out_path}\")\n",
    "    print(f\"‚úÖ Experiment for sequence_length={prefix_length} completed in {results['runtime_seconds']}s.\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# Run all sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [2500]\n",
    "for seq_len in sequence_lengths:\n",
    "    run_experiment(seq_len)\n",
    "\n",
    "print(\"\\nüéØ All experiments completed! Results saved in /LSTM model/SCap/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f723fcd-2962-405b-89c0-3264dbe8a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üöÄ Experiment 3: LSTM + Activity Transitions + Optuna (Fixed Oversampling)\n",
    "# =====================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# =====================================================\n",
    "# Setup & Configuration\n",
    "# =====================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# =====================================================\n",
    "# Load Event Log\n",
    "# =====================================================\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "event_log = import_xes(\"BPI Challenge 2018.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "# =====================================================\n",
    "# Create Activity Sequences per Resource\n",
    "# =====================================================\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, group in df.groupby('org:resource'):\n",
    "        acts = group['concept:name'].tolist()\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df[\"next_activity\"] = next_activities\n",
    "    seq_df[\"org:resource\"] = resources\n",
    "    return seq_df\n",
    "\n",
    "# =====================================================\n",
    "# Create Transition-Based Features\n",
    "# =====================================================\n",
    "def create_transition_features(sequences_df):\n",
    "    unique_activities = sorted(set(sequences_df.drop(columns=['next_activity','org:resource']).values.flatten()))\n",
    "    all_transitions = [(a, b) for a in unique_activities for b in unique_activities]\n",
    "    transition_counts = []\n",
    "    for _, row in sequences_df.iterrows():\n",
    "        transitions = defaultdict(int)\n",
    "        acts = row.drop(labels=['next_activity','org:resource']).dropna().tolist()\n",
    "        for i in range(len(acts)-1):\n",
    "            transitions[(acts[i], acts[i+1])] += 1\n",
    "        row_counts = {f\"{a}->{b}\": transitions.get((a,b),0) for (a,b) in all_transitions}\n",
    "        transition_counts.append(row_counts)\n",
    "    return pd.concat([sequences_df.reset_index(drop=True), pd.DataFrame(transition_counts)], axis=1)\n",
    "\n",
    "# =====================================================\n",
    "# Proportional Oversampling (Training Only)\n",
    "# =====================================================\n",
    "def proportional_sampling(X, y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / count))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    X_bal = np.vstack(X_resampled)\n",
    "    y_bal = np.hstack(y_resampled)\n",
    "    idx = np.random.permutation(len(y_bal))\n",
    "    return X_bal[idx], y_bal[idx]\n",
    "\n",
    "# =====================================================\n",
    "# LSTM Model\n",
    "# =====================================================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size // 2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size // 2, num_classes)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# =====================================================\n",
    "# Training Function\n",
    "# =====================================================\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=None):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_wts = model.state_dict()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            if torch.isnan(loss):\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        count = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "                count += 1\n",
    "        val_loss /= max(count, 1)\n",
    "\n",
    "        print(f\"üåÄ Trial {trial_num} | Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_wts = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1} (no improvement).\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model\n",
    "\n",
    "# =====================================================\n",
    "# Run One Experiment\n",
    "# =====================================================\n",
    "def run_experiment(prefix_length):\n",
    "    print(f\"\\nüöÄ Running experiment for prefix_length = {prefix_length}\")\n",
    "    start_time = time.time()\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "    if sequences_df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: not enough data.\")\n",
    "        return\n",
    "    sequences_df = create_transition_features(sequences_df)\n",
    "\n",
    "    # Encode all object columns\n",
    "    encoders = {}\n",
    "    for col in sequences_df.columns:\n",
    "        if sequences_df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            sequences_df[col] = le.fit_transform(sequences_df[col].astype(str))\n",
    "            encoders[col] = le\n",
    "\n",
    "    # Split features/labels\n",
    "    X = sequences_df.drop(columns=['next_activity', 'org:resource']).values.astype(np.float32)\n",
    "    y = sequences_df['next_activity'].values.astype(str)  # keep as string for LabelEncoder\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # Fit LabelEncoder on training labels only\n",
    "    le_target = LabelEncoder()\n",
    "    y_train_enc = le_target.fit_transform(y_train)\n",
    "\n",
    "    # Filter validation to only seen classes\n",
    "    valid_mask = np.isin(y_val, le_target.classes_)\n",
    "    X_val = X_val[valid_mask]\n",
    "    y_val = y_val[valid_mask]\n",
    "    y_val_enc = le_target.transform(y_val)\n",
    "\n",
    "    # Oversample training only\n",
    "    X_train_flat = X_train.reshape((X_train.shape[0], X_train.shape[2]))\n",
    "    X_train_res, y_train_res = proportional_sampling(X_train_flat, y_train_enc)\n",
    "    X_train_res = np.expand_dims(X_train_res, axis=1)\n",
    "\n",
    "    num_classes = len(le_target.classes_)\n",
    "\n",
    "    # Optuna Hyperparameter Tuning\n",
    "    def objective(trial):\n",
    "        trial_num = trial.number + 1\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 32, 192, step=32)\n",
    "        lr = trial.suggest_categorical(\"lr\", [1e-4, 5e-4, 1e-3])\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "\n",
    "        print(f\"\\nüî• Starting Trial {trial_num} | hidden={hidden_size}, lr={lr}, opt={optimizer_name}\")\n",
    "\n",
    "        model = LSTMModel(X_train_res.shape[2], hidden_size, num_classes).to(device)\n",
    "        if optimizer_name == \"adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        elif optimizer_name == \"rmsprop\":\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train_res), torch.tensor(y_train_res)), batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val_enc)), batch_size=32)\n",
    "        model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=trial_num)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, _ in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "        acc = accuracy_score(y_val_enc, y_pred)\n",
    "        print(f\"‚úÖ Trial {trial_num} finished with Accuracy: {acc:.4f}\")\n",
    "        return acc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=15, catch=(Exception,))\n",
    "    if len(study.trials) == 0 or study.best_trial is None:\n",
    "        print(\"‚ö†Ô∏è No successful trials. Skipping saving metrics.\")\n",
    "        return\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"\\nüèÜ Best Hyperparameters for seq {prefix_length}: {best_params}\")\n",
    "\n",
    "    # Final Training with Best Params\n",
    "    hidden_size = best_params[\"hidden_size\"]\n",
    "    lr = best_params[\"lr\"]\n",
    "    optimizer_name = best_params[\"optimizer\"]\n",
    "\n",
    "    model = LSTMModel(X_train_res.shape[2], hidden_size, num_classes).to(device)\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train_res), torch.tensor(y_train_res)), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val_enc)), batch_size=32)\n",
    "    model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=50, patience=5, trial_num=\"final\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_val_enc, y_pred),\n",
    "        \"precision\": precision_score(y_val_enc, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(y_val_enc, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_val_enc, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"num_samples\": len(y_train_res),\n",
    "        \"sequence_length\": prefix_length\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"sequence_length\": prefix_length,\n",
    "        \"best_hyperparameters\": best_params,\n",
    "        \"metrics\": metrics,\n",
    "        \"runtime_seconds\": round(time.time() - start_time, 2)\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"results/BPIC2018/LSTM model/S2g\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2018/LSTM model/S2g/lstm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"\\nüìä Evaluation Results:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"   {k}: {v:.4f}\")\n",
    "    print(f\"üíæ Results saved to {out_path}\")\n",
    "    print(f\"‚úÖ Experiment for sequence_length={prefix_length} completed in {results['runtime_seconds']}s.\\n\")\n",
    "\n",
    "# =====================================================\n",
    "# Run All Experiments\n",
    "# =====================================================\n",
    "sequence_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000, 2500]\n",
    "for seq_len in sequence_lengths:\n",
    "    run_experiment(seq_len)\n",
    "\n",
    "print(\"\\nüéØ All experiments completed! Results saved in /results/BPIC2019/LSTM model/S2g_fixed/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c67db3-c806-48eb-8141-6073f9f5db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# ‚úÖ Experiment 4 (Logging Enhanced, Fixed Encoding):\n",
    "# LSTM + Transition & Repeat Features + Optuna\n",
    "# =====================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import optuna\n",
    "import pm4py\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Environment Setup\n",
    "# =====================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Load Event Log\n",
    "# =====================================================\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2013_incidents.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Log loaded: {len(df)} events, {df['org:resource'].nunique()} resources.\")\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Create Activity Sequences\n",
    "# =====================================================\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, group in df.groupby('org:resource'):\n",
    "        acts = group['concept:name'].tolist()\n",
    "        if len(acts) > prefix_length:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(resource)\n",
    "    if not sequences:\n",
    "        return pd.DataFrame()\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df[\"next_activity\"] = next_activities\n",
    "    seq_df[\"org:resource\"] = resources\n",
    "    return seq_df\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ Create Transition + Repeat Pattern Features\n",
    "# =====================================================\n",
    "def create_transition_and_repeat_features(sequences_df):\n",
    "    unique_activities = sorted(set(sequences_df.drop(columns=['next_activity','org:resource']).values.flatten()))\n",
    "    all_transitions = [(a,b) for a in unique_activities for b in unique_activities]\n",
    "\n",
    "    transition_counts = []\n",
    "    repeat_features = []\n",
    "\n",
    "    for _, row in sequences_df.iterrows():\n",
    "        transitions = defaultdict(int)\n",
    "        acts = row.drop(labels=['next_activity','org:resource']).dropna().tolist()\n",
    "\n",
    "        # Count transitions\n",
    "        for i in range(len(acts)-1):\n",
    "            transitions[(acts[i], acts[i+1])] += 1\n",
    "        row_counts = {f\"{a}->{b}\": transitions.get((a,b),0) for (a,b) in all_transitions}\n",
    "        transition_counts.append(row_counts)\n",
    "\n",
    "        # Repeat pattern features\n",
    "        current_run = 1\n",
    "        run_lengths = []\n",
    "        for i in range(1, len(acts)):\n",
    "            if acts[i] == acts[i-1]:\n",
    "                current_run += 1\n",
    "            else:\n",
    "                run_lengths.append(current_run)\n",
    "                current_run = 1\n",
    "        run_lengths.append(current_run)\n",
    "        repeat_features.append({\n",
    "            \"avg_run_length\": np.mean(run_lengths),\n",
    "            \"num_runs\": len(run_lengths)\n",
    "        })\n",
    "\n",
    "    transitions_df = pd.DataFrame(transition_counts)\n",
    "    repeat_df = pd.DataFrame(repeat_features)\n",
    "    return pd.concat([sequences_df.reset_index(drop=True), transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ Proportional Oversampling\n",
    "# =====================================================\n",
    "def proportional_sampling(X, y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / count))\n",
    "        X_resampled.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_resampled.append(np.tile(y_cls, n_repeat))\n",
    "    X_bal = np.vstack(X_resampled)\n",
    "    y_bal = np.hstack(y_resampled)\n",
    "    idx = np.random.permutation(len(y_bal))\n",
    "    return X_bal[idx], y_bal[idx]\n",
    "\n",
    "# =====================================================\n",
    "# 6Ô∏è‚É£ LSTM Model\n",
    "# =====================================================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size//2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size//2, num_classes)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# =====================================================\n",
    "# 7Ô∏è‚É£ Training Function (with logs)\n",
    "# =====================================================\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=None):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_wts = model.state_dict()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            if torch.isnan(loss):\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        count = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "                count += 1\n",
    "        val_loss /= max(count, 1)\n",
    "\n",
    "        print(f\"üåÄ Trial {trial_num} | Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_wts = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1} (no improvement).\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model\n",
    "\n",
    "# =====================================================\n",
    "# 8Ô∏è‚É£ Run One Experiment\n",
    "# =====================================================\n",
    "def run_experiment(prefix_length):\n",
    "    print(f\"\\nüöÄ Running Experiment 4 for prefix_length = {prefix_length}\")\n",
    "    start_time = time.time()\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "    if sequences_df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping prefix_length={prefix_length}: not enough data.\")\n",
    "        return\n",
    "    sequences_df = create_transition_and_repeat_features(sequences_df)\n",
    "\n",
    "    # Encode object features except target\n",
    "    for col in sequences_df.columns:\n",
    "        if sequences_df[col].dtype == 'object' and col not in ['next_activity']:\n",
    "            le = LabelEncoder()\n",
    "            sequences_df[col] = le.fit_transform(sequences_df[col].astype(str))\n",
    "\n",
    "    # Separate features and raw labels\n",
    "    X = sequences_df.drop(columns=['next_activity','org:resource']).values.astype(np.float32)\n",
    "    y_raw = sequences_df['next_activity'].astype(str).values\n",
    "\n",
    "    # Split before encoding y\n",
    "    X_train, X_val, y_train_raw, y_val_raw = train_test_split(X, y_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Encode y only on training labels\n",
    "    le_y = LabelEncoder()\n",
    "    y_train = le_y.fit_transform(y_train_raw)\n",
    "    y_val = np.array([le_y.transform([label])[0] if label in le_y.classes_ else -1 for label in y_val_raw])\n",
    "    mask = y_val != -1\n",
    "    X_val = X_val[mask]\n",
    "    y_val = y_val[mask]\n",
    "\n",
    "    # Balance only the training data\n",
    "    X_train, y_train = proportional_sampling(X_train, y_train)\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_val = np.expand_dims(X_val, axis=1)\n",
    "    num_classes = len(le_y.classes_)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Optuna Hyperparameter Tuning\n",
    "    # -------------------------------\n",
    "    def objective(trial):\n",
    "        trial_num = trial.number + 1\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 32, 192, step=32)\n",
    "        lr = trial.suggest_categorical(\"lr\", [1e-4, 5e-4, 1e-3])\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "\n",
    "        print(f\"\\nüî• Starting Trial {trial_num} | hidden={hidden_size}, lr={lr}, opt={optimizer_name}\")\n",
    "\n",
    "        model = LSTMModel(X_train.shape[2], hidden_size, num_classes).to(device)\n",
    "        if optimizer_name == \"adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        elif optimizer_name == \"rmsprop\":\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "        model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=15, patience=3, trial_num=trial_num)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, _ in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        print(f\"‚úÖ Trial {trial_num} finished with Accuracy: {acc:.4f}\")\n",
    "        return acc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=18, catch=(Exception,))\n",
    "    if len(study.trials) == 0 or study.best_trial is None:\n",
    "        print(\"‚ö†Ô∏è No successful trials. Skipping saving metrics.\")\n",
    "        return\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"\\nüèÜ Best Hyperparameters for seq {prefix_length}: {best_params}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Final Training with Best Params\n",
    "    # -------------------------------\n",
    "    hidden_size = best_params[\"hidden_size\"]\n",
    "    lr = best_params[\"lr\"]\n",
    "    optimizer_name = best_params[\"optimizer\"]\n",
    "\n",
    "    model = LSTMModel(X_train.shape[2], hidden_size, num_classes).to(device)\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)), batch_size=32)\n",
    "    model = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=50, patience=5, trial_num=\"final\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Evaluation\n",
    "    # -------------------------------\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "        \"precision\": precision_score(y_val, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(y_val, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_val, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"num_samples\": len(y_train),\n",
    "        \"sequence_length\": prefix_length\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"sequence_length\": prefix_length,\n",
    "        \"best_hyperparameters\": best_params,\n",
    "        \"metrics\": metrics,\n",
    "        \"runtime_seconds\": round(time.time() - start_time, 2)\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"results/BPIC2013/LSTM model/S2gR\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2013/LSTM model/S2gR/lstm_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"\\nüìä Evaluation Results:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"   {k}: {v:.4f}\")\n",
    "    print(f\"üíæ Results saved to {out_path}\")\n",
    "    print(f\"‚úÖ Experiment for sequence_length={prefix_length} completed in {results['runtime_seconds']}s.\\n\")\n",
    "\n",
    "# =====================================================\n",
    "# 9Ô∏è‚É£ Run All Experiments\n",
    "# =====================================================\n",
    "sequence_lengths = [10, 20, 30, 40, 50, 75, 100, 125, 150]\n",
    "for seq_len in sequence_lengths:\n",
    "    run_experiment(seq_len)\n",
    "\n",
    "print(\"\\nüéâ All experiments completed successfully for Experiment 4!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5021f1-d0f5-4759-8ff7-d27899e432d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Experiment 1 (baseline encoding, CPU-based with GridSearchCV, fixed oversampling)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2013_incidents.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            sequences.append(activities[:prefix_length])\n",
    "            next_activities.append(activities[prefix_length])\n",
    "            resources.append(resource)\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling (training set only)\n",
    "# --------------------------\n",
    "def oversample_proportional(X, y):\n",
    "    counts = y.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(pd.concat([X_cls]*n_repeat, axis=0))\n",
    "        y_resampled.append(pd.concat([y_cls]*n_repeat, axis=0))\n",
    "    X_bal = pd.concat(X_resampled, axis=0).reset_index(drop=True)\n",
    "    y_bal = pd.concat(y_resampled, axis=0).reset_index(drop=True)\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# --------------------------\n",
    "# Hyperparameter grid\n",
    "# --------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# Run experiments for multiple sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [10, 20, 30, 40, 50, 75, 100, 125, 150]\n",
    "\n",
    "for prefix_length in sequence_lengths:\n",
    "    print(f\"\\nüöÄ Running Random Forest experiment: sequence length = {prefix_length}\")\n",
    "\n",
    "    # Create activity sequences\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "\n",
    "    # Encode activities as numeric\n",
    "    label_encoder = LabelEncoder()\n",
    "    activity_cols = [f\"activity_{i+1}\" for i in range(prefix_length)]\n",
    "    all_activities = sequences_df[activity_cols + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_activities)\n",
    "    for col in activity_cols + ['next_activity']:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # Features and target\n",
    "    X = sequences_df[activity_cols]\n",
    "    y = sequences_df['next_activity']\n",
    "\n",
    "    # --------------------------\n",
    "    # Split train/test BEFORE oversampling\n",
    "    # --------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Oversample only the training set\n",
    "    X_train, y_train = oversample_proportional(X_train, y_train)\n",
    "\n",
    "    # --------------------------\n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    # --------------------------\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2013/RandomForest/Baseline encoding\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2013/RandomForest/Baseline encoding/rf_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_params\": best_params,\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1)\n",
    "            }\n",
    "        }, f, indent=4)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ All Random Forest experiments completed with GridSearchCV (fixed oversampling)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2f0d2-b8cf-48c8-b0ad-9c14c0dded03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Experiment 2 (RA diversity matrix, CPU-based with GridSearchCV, fixed oversampling)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2019.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            sequences.append(activities[:prefix_length])\n",
    "            next_activities.append(activities[prefix_length])\n",
    "            resources.append(resource)\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "# --------------------------\n",
    "# RA Diversity Matrix\n",
    "# --------------------------\n",
    "def create_diversity_matrix(log):\n",
    "    activity_counts = log.pivot_table(\n",
    "        index='org:resource',\n",
    "        columns='concept:name',\n",
    "        aggfunc='size',\n",
    "        fill_value=0\n",
    "    )\n",
    "    activity_counts.reset_index(inplace=True)\n",
    "    return activity_counts\n",
    "\n",
    "ra_matrix = create_diversity_matrix(df)\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling (only on training set)\n",
    "# --------------------------\n",
    "def oversample_proportional(X, y):\n",
    "    counts = y.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(pd.concat([X_cls]*n_repeat, axis=0))\n",
    "        y_resampled.append(pd.concat([y_cls]*n_repeat, axis=0))\n",
    "    X_bal = pd.concat(X_resampled, axis=0).reset_index(drop=True)\n",
    "    y_bal = pd.concat(y_resampled, axis=0).reset_index(drop=True)\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# --------------------------\n",
    "# Run experiments for multiple sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "for prefix_length in sequence_lengths:\n",
    "    print(f\"\\nüöÄ Running Random Forest experiment with RA diversity matrix: sequence length = {prefix_length}\")\n",
    "\n",
    "    # Create activity sequences\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "\n",
    "    # Encode activities numerically\n",
    "    label_encoder = LabelEncoder()\n",
    "    activity_cols = [f\"activity_{i+1}\" for i in range(prefix_length)]\n",
    "    all_activities = sequences_df[activity_cols + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_activities)\n",
    "    for col in activity_cols + ['next_activity']:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # Merge RA matrix into sequences_df\n",
    "    X_activities = sequences_df[activity_cols]\n",
    "    X_ra = sequences_df[['org:resource']].merge(ra_matrix, on='org:resource', how='left').drop(columns=['org:resource'])\n",
    "    X = pd.concat([X_activities, X_ra], axis=1)\n",
    "\n",
    "    # Target\n",
    "    y = sequences_df['next_activity']\n",
    "\n",
    "    # --------------------------\n",
    "    # Split train/test BEFORE oversampling\n",
    "    # --------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Oversample only the training set\n",
    "    X_train, y_train = oversample_proportional(X_train, y_train)\n",
    "\n",
    "    # --------------------------\n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    # --------------------------\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    grid_search = GridSearchCV(\n",
    "        rf_model,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best_rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2019/RandomForest/SCap\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2019/RandomForest/SCap/rf_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_params\": best_params,\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1)\n",
    "            }\n",
    "        }, f, indent=4)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ All Random Forest experiments with RA diversity matrix completed (fixed oversampling)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfe176-bd90-4737-b8f5-dae6250c1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest experiment 3 (transition features, CPU-based with GridSearchCV, fixed oversampling)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pm4py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2019.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            sequences.append(activities[:prefix_length])\n",
    "            next_activities.append(activities[prefix_length])\n",
    "            resources.append(resource)\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "# --------------------------\n",
    "# Transition features\n",
    "# --------------------------\n",
    "def create_transition_features(sequences_df):\n",
    "    unique_activities = sorted(set(sequences_df.drop(columns=['next_activity', 'org:resource']).values.flatten()) - {None})\n",
    "    all_transitions = [(a, b) for a in unique_activities for b in unique_activities]\n",
    "\n",
    "    transition_counts = []\n",
    "    for _, row in sequences_df.iterrows():\n",
    "        transitions = defaultdict(int)\n",
    "        activities = row.drop(labels=['next_activity', 'org:resource']).dropna().tolist()\n",
    "        for i in range(len(activities) - 1):\n",
    "            transitions[(activities[i], activities[i + 1])] += 1\n",
    "        row_counts = {f\"{a}->{b}\": transitions.get((a, b), 0) for (a, b) in all_transitions}\n",
    "        transition_counts.append(row_counts)\n",
    "    return pd.concat([sequences_df.reset_index(drop=True), pd.DataFrame(transition_counts)], axis=1)\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling (training set only)\n",
    "# --------------------------\n",
    "def oversample_proportional(X, y):\n",
    "    counts = y.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(pd.concat([X_cls]*n_repeat, axis=0))\n",
    "        y_resampled.append(pd.concat([y_cls]*n_repeat, axis=0))\n",
    "    X_bal = pd.concat(X_resampled, axis=0).reset_index(drop=True)\n",
    "    y_bal = pd.concat(y_resampled, axis=0).reset_index(drop=True)\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# --------------------------\n",
    "# Run experiments for multiple sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "for prefix_length in sequence_lengths:\n",
    "    print(f\"\\nüöÄ Running Random Forest experiment with transition features: sequence length = {prefix_length}\")\n",
    "\n",
    "    # Create activity sequences\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "\n",
    "    # Encode activities numerically\n",
    "    label_encoder = LabelEncoder()\n",
    "    activity_cols = [f\"activity_{i+1}\" for i in range(prefix_length)]\n",
    "    all_activities = sequences_df[activity_cols + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_activities)\n",
    "    for col in activity_cols + ['next_activity']:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # Add transition features\n",
    "    sequences_df = create_transition_features(sequences_df)\n",
    "    X = sequences_df.drop(columns=['next_activity', 'org:resource'])\n",
    "    y = sequences_df['next_activity']\n",
    "\n",
    "    # --------------------------\n",
    "    # Split train/test BEFORE oversampling\n",
    "    # --------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Oversample only the training set\n",
    "    X_train, y_train = oversample_proportional(X_train, y_train)\n",
    "\n",
    "    # --------------------------\n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    # --------------------------\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best_rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2019/RandomForest/S2g\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2019/RandomForest/S2g/rf_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1)\n",
    "            }\n",
    "        }, f, indent=4)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ All Random Forest experiments with transition features completed (fixed oversampling)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ac402-48d2-424e-af3a-fa35210caa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest experiment 4 (transition + repeat features, fixed oversampling & splitting)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pm4py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"BPI_Challenge_2019.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            sequences.append(activities[:prefix_length])\n",
    "            next_activities.append(activities[prefix_length])\n",
    "            resources.append(resource)\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities\n",
    "    sequences_df['org:resource'] = resources\n",
    "    return sequences_df\n",
    "\n",
    "# --------------------------\n",
    "# Transition + Repeat Features\n",
    "# --------------------------\n",
    "def create_transition_and_repeat_features(sequences_df):\n",
    "    unique_activities = sorted(\n",
    "        set(sequences_df.drop(columns=[\"next_activity\", \"org:resource\"]).values.flatten()) - {None}\n",
    "    )\n",
    "    all_possible_transitions = [(a, b) for a in unique_activities for b in unique_activities]\n",
    "\n",
    "    transition_counts = []\n",
    "    repeat_pattern_features = []\n",
    "\n",
    "    for _, row in sequences_df.iterrows():\n",
    "        transitions = defaultdict(int)\n",
    "        activities = row.drop(labels=[\"next_activity\", \"org:resource\"]).dropna().tolist()\n",
    "\n",
    "        # Transition counts\n",
    "        for i in range(len(activities) - 1):\n",
    "            transitions[(activities[i], activities[i + 1])] += 1\n",
    "        row_counts = {f\"{a}->{b}\": transitions.get((a, b), 0) for (a, b) in all_possible_transitions}\n",
    "        transition_counts.append(row_counts)\n",
    "\n",
    "        # Repeat pattern features\n",
    "        current_run = 1\n",
    "        run_lengths = []\n",
    "        for i in range(1, len(activities)):\n",
    "            if activities[i] == activities[i - 1]:\n",
    "                current_run += 1\n",
    "            else:\n",
    "                run_lengths.append(current_run)\n",
    "                current_run = 1\n",
    "        run_lengths.append(current_run)\n",
    "        repeat_pattern_features.append({\n",
    "            \"avg_run_length\": np.mean(run_lengths),\n",
    "            \"num_runs\": len(run_lengths)\n",
    "        })\n",
    "\n",
    "    transitions_df = pd.DataFrame(transition_counts)\n",
    "    repeat_df = pd.DataFrame(repeat_pattern_features)\n",
    "    return pd.concat([sequences_df.reset_index(drop=True), transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling (training set only)\n",
    "# --------------------------\n",
    "def oversample_proportional(X, y):\n",
    "    counts = y.value_counts()\n",
    "    max_count = counts.max()\n",
    "    X_resampled, y_resampled = [], []\n",
    "    for cls in counts.index:\n",
    "        cls_mask = (y == cls)\n",
    "        X_cls, y_cls = X[cls_mask], y[cls_mask]\n",
    "        n_repeat = int(np.ceil(max_count / len(y_cls)))\n",
    "        X_resampled.append(pd.concat([X_cls]*n_repeat, axis=0))\n",
    "        y_resampled.append(pd.concat([y_cls]*n_repeat, axis=0))\n",
    "    X_bal = pd.concat(X_resampled, axis=0).reset_index(drop=True)\n",
    "    y_bal = pd.concat(y_resampled, axis=0).reset_index(drop=True)\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# --------------------------\n",
    "# Run experiments for multiple sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "for prefix_length in sequence_lengths:\n",
    "    print(f\"\\nüöÄ Running Random Forest experiment with transition + repeat features: sequence length = {prefix_length}\")\n",
    "\n",
    "    # Create activity sequences\n",
    "    sequences_df = create_activity_sequences(df, prefix_length)\n",
    "\n",
    "    # Encode activities numerically\n",
    "    label_encoder = LabelEncoder()\n",
    "    activity_cols = [f\"activity_{i+1}\" for i in range(prefix_length)]\n",
    "    all_activities = sequences_df[activity_cols + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_activities)\n",
    "    for col in activity_cols + ['next_activity']:\n",
    "        sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "    # Add transition + repeat features\n",
    "    sequences_df = create_transition_and_repeat_features(sequences_df)\n",
    "    X = sequences_df.drop(columns=['next_activity', 'org:resource'])\n",
    "    y = sequences_df['next_activity']\n",
    "\n",
    "    # --------------------------\n",
    "    # Split train/test BEFORE oversampling\n",
    "    # --------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Oversample only the training set\n",
    "    X_train, y_train = oversample_proportional(X_train, y_train)\n",
    "\n",
    "    # --------------------------\n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    # --------------------------\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best_rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(\"results/BPIC2019/RandomForest/S2gR\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2019/RandomForest/S2gR/rf_seq_{prefix_length}.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1)\n",
    "            }\n",
    "        }, f, indent=4)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ All Random Forest experiments with transition + repeat features completed (fixed oversampling)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2fddf-152b-40da-af23-1029c0e3443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# ‚úÖ Experiment 2: LSTM + RA Binary Features (NaN-safe)\n",
    "# =====================================================\n",
    "\n",
    "import os, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import keras_tuner as kt\n",
    "\n",
    "# --------------------------\n",
    "# Environment & GPU setup\n",
    "# --------------------------\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "set_global_policy(\"mixed_float16\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# --------------------------\n",
    "# Load event log\n",
    "# --------------------------\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "event_log = import_xes(\"BPI Challenge 2017.xes\")\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp']).reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Resource-Activity binary matrix\n",
    "# --------------------------\n",
    "def create_diversity_matrix(log):\n",
    "    mat = log.pivot_table(index='org:resource', columns='concept:name', aggfunc='size', fill_value=0)\n",
    "    mat.reset_index(inplace=True)\n",
    "    return mat\n",
    "\n",
    "ra_div_matrix = create_diversity_matrix(event_log)\n",
    "ra_div_binary = ra_div_matrix.copy()\n",
    "ra_div_binary.iloc[:, 1:] = (ra_div_binary.iloc[:, 1:] > 0).astype(int)\n",
    "ra_features = ra_div_matrix.columns[1:].tolist()  # Names of RA binary features\n",
    "\n",
    "# --------------------------\n",
    "# Sequence creation\n",
    "# --------------------------\n",
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences, next_activities, resources = [], [], []\n",
    "    for res, res_df in df.groupby('org:resource'):\n",
    "        acts = res_df['concept:name'].values\n",
    "        if len(acts) >= prefix_length + 1:\n",
    "            sequences.append(acts[:prefix_length])\n",
    "            next_activities.append(acts[prefix_length])\n",
    "            resources.append(res)\n",
    "    seq_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    seq_df['next_activity'] = next_activities\n",
    "    seq_df['org:resource'] = resources\n",
    "    return seq_df\n",
    "\n",
    "# --------------------------\n",
    "# Proportional oversampling\n",
    "# --------------------------\n",
    "def proportional_sampling(X, y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    X_res, y_res = [], []\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        mask = (y == cls)\n",
    "        X_cls, y_cls = X[mask], y[mask]\n",
    "        n_repeat = int(np.ceil(max_count / cnt))\n",
    "        X_res.append(np.tile(X_cls, (n_repeat, 1)))\n",
    "        y_res.append(np.tile(y_cls, n_repeat))\n",
    "    X_bal = np.vstack(X_res)\n",
    "    y_bal = np.hstack(y_res)\n",
    "    idx = np.random.permutation(len(y_bal))\n",
    "    return X_bal[idx], y_bal[idx]\n",
    "\n",
    "# --------------------------\n",
    "# Run experiment\n",
    "# --------------------------\n",
    "def run_experiment(prefix_length):\n",
    "    print(f\"\\nüöÄ Running LSTM + RA binary for prefix={prefix_length}\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 1Ô∏è‚É£ Sequences\n",
    "    seq_df = create_activity_sequences(df, prefix_length)\n",
    "    if seq_df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping prefix {prefix_length}: not enough data\")\n",
    "        return\n",
    "\n",
    "    # 2Ô∏è‚É£ Merge RA binary features\n",
    "    ra_filtered = ra_div_binary[ra_div_binary['org:resource'].isin(seq_df['org:resource'])].reset_index(drop=True)\n",
    "    merged_df = pd.concat([seq_df.reset_index(drop=True), ra_filtered.iloc[:, 1:]], axis=1)\n",
    "\n",
    "    # 3Ô∏è‚É£ Encode activities\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_acts = merged_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']].values.flatten()\n",
    "    label_encoder.fit(all_acts)\n",
    "    for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']:\n",
    "        merged_df[col] = label_encoder.transform(merged_df[col])\n",
    "\n",
    "    # 4Ô∏è‚É£ Prepare X (sequences + RA) and y\n",
    "    X_seq = merged_df[[f\"activity_{i+1}\" for i in range(prefix_length)]].values.astype(np.float32)\n",
    "    X_ra = merged_df[ra_features].values.astype(np.float32)\n",
    "    y = merged_df['next_activity'].values.astype(np.int32)\n",
    "\n",
    "    # Scale sequence features only\n",
    "    scaler = StandardScaler()\n",
    "    X_seq = scaler.fit_transform(X_seq)\n",
    "\n",
    "    # Oversample\n",
    "    X_seq, y = proportional_sampling(X_seq, y)\n",
    "    X_ra = np.tile(X_ra, (int(np.ceil(len(X_seq)/len(X_ra))),1))[:len(X_seq)]\n",
    "\n",
    "    # Expand dims for LSTM\n",
    "    X_seq = np.expand_dims(X_seq, axis=-1)  # (samples, seq_len, 1)\n",
    "\n",
    "    # Train/test split\n",
    "    X_seq_train, X_seq_test, X_ra_train, X_ra_test, y_train, y_test = train_test_split(\n",
    "        X_seq, X_ra, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(f\"‚úÖ Data ready ‚Äî Train: {len(X_seq_train)}, Test: {len(X_seq_test)}\")\n",
    "\n",
    "    # --------------------------\n",
    "    # Model builder\n",
    "    # --------------------------\n",
    "    def build_model(hp):\n",
    "        seq_input = layers.Input(shape=(X_seq_train.shape[1],1), name=\"seq_input\")\n",
    "        x = layers.LSTM(hp.Int(\"units\", 32, 192, step=32), return_sequences=True)(seq_input)\n",
    "        x = layers.LSTM(hp.Int(\"units\", 16, 96, step=16))(x)\n",
    "\n",
    "        # RA features\n",
    "        ra_input = layers.Input(shape=(X_ra_train.shape[1],), name=\"ra_input\")\n",
    "\n",
    "        # Concatenate\n",
    "        concat = layers.Concatenate()([x, ra_input])\n",
    "\n",
    "        out = layers.Dense(len(np.unique(y)), activation=\"softmax\", dtype=\"float32\")(concat)\n",
    "        model = models.Model(inputs=[seq_input, ra_input], outputs=out)\n",
    "\n",
    "        lr = hp.Choice(\"learning_rate\", [1e-4, 5e-5, 1e-5])\n",
    "        opt_choice = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "        if opt_choice==\"adam\":\n",
    "            optimizer = optimizers.Adam(learning_rate=lr)\n",
    "        elif opt_choice==\"rmsprop\":\n",
    "            optimizer = optimizers.RMSprop(learning_rate=lr)\n",
    "        else:\n",
    "            optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        hp.Choice(\"batch_size\", [16,32,64,128])\n",
    "        return model\n",
    "\n",
    "    # --------------------------\n",
    "    # Hyperparameter tuning\n",
    "    # --------------------------\n",
    "    tuner = kt.RandomSearch(\n",
    "        build_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory=\"tuner_exp2_nanfix\",\n",
    "        project_name=f\"seq_{prefix_length}\",\n",
    "        overwrite=True\n",
    "    )\n",
    "    stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    tuner.search([X_seq_train, X_ra_train], y_train,\n",
    "                 validation_split=0.2, epochs=50, batch_size=32, callbacks=[stop], verbose=1)\n",
    "\n",
    "    # --------------------------\n",
    "    # Evaluate best model\n",
    "    # --------------------------\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "    best_model = tuner.get_best_models(1)[0]\n",
    "    batch_size = best_hp.values.get(\"batch_size\",32)\n",
    "\n",
    "    y_pred_prob = best_model.predict([X_seq_test, X_ra_test], batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)),\n",
    "        \"f1_score\": float(f1_score(y_test, y_pred, average=\"weighted\", zero_division=0))\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüìä Metrics: {metrics}\")\n",
    "\n",
    "    # --------------------------\n",
    "    # Save results\n",
    "    # --------------------------\n",
    "    os.makedirs(\"results/BPIC2017/LSTM model/SCap\", exist_ok=True)\n",
    "    out_path = f\"results/BPIC2017/LSTM model/SCap/lstm_seq_{prefix_length}.json\"\n",
    "    with open(out_path,\"w\") as f:\n",
    "        json.dump({\n",
    "            \"sequence_length\": prefix_length,\n",
    "            \"best_hyperparameters\": best_hp.values,\n",
    "            \"batch_size_used\": batch_size,\n",
    "            \"metrics\": metrics,\n",
    "            \"runtime_seconds\": round(time.time()-t0,2)\n",
    "        }, f, indent=4)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "    print(f\"‚úÖ Done in {round(time.time()-t0,2)}s\")\n",
    "\n",
    "# --------------------------\n",
    "# Run all sequence lengths\n",
    "# --------------------------\n",
    "sequence_lengths = [100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1500, 2000]\n",
    "for seq_len in sequence_lengths:\n",
    "    run_experiment(seq_len)\n",
    "\n",
    "print(\"\\nüéâ All experiments completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
